{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MUST USE GRADSCALER AND AUTOCAST OR TRAINING TAKES 3X AS LONG\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import spatial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from timm.utils import AverageMeter\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import warnings\n",
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.multiprocessing import Process\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = 'vit_large_patch16_224'\n",
    "    input_size = 224\n",
    "    batch_size = 128\n",
    "    num_epochs = 25\n",
    "    lr = 5e-4\n",
    "    seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['image_path'])\n",
    "        image = self.transform(image)\n",
    "        prompt = row['prompt']\n",
    "        return image, prompt\n",
    "\n",
    "\n",
    "class DiffusionCollator:\n",
    "    def __init__(self):\n",
    "        self.st_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        images, prompts = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        prompt_embeddings = self.st_model.encode(prompts, show_progress_bar=False, convert_to_tensor=True)\n",
    "        return images, prompt_embeddings\n",
    "    \n",
    "\n",
    "def get_dataloaders(trn_df, val_df, input_size, batch_size, rank, world_size, seed=21):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    trn_dataset = DiffusionDataset(trn_df, train_transform)\n",
    "    val_dataset = DiffusionDataset(val_df, val_transform)\n",
    "    collator = DiffusionCollator()\n",
    "\n",
    "    train_sampler = DistributedSampler(trn_dataset, num_replicas=world_size, rank=rank, seed=seed, shuffle=True)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=rank, seed=seed, shuffle=False)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = DataLoader(\n",
    "        dataset=trn_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=12,\n",
    "        drop_last=True,\n",
    "        collate_fn=collator,\n",
    "        sampler=train_sampler)\n",
    "        \n",
    "    dataloaders['val'] = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=12,\n",
    "        drop_last=False,\n",
    "        collate_fn=collator,\n",
    "        sampler=val_sampler)\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(y_trues, y_preds):\n",
    "    return np.mean([\n",
    "        1 - spatial.distance.cosine(y_true, y_pred) \n",
    "        for y_true, y_pred in zip(y_trues, y_preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, world_size, trn_df, val_df, model_name, input_size, batch_size, num_epochs, lr):\n",
    "    \n",
    "    # Setup the distributed process group\n",
    "    dist.init_process_group('nccl', rank=rank, world_size=world_size)\n",
    "    dist.barrier()\n",
    "    print(\"all processes setup\")\n",
    "\n",
    "    # Modify the batch size for distributed training\n",
    "    batch_size = batch_size // world_size\n",
    "\n",
    "    dataloaders = get_dataloaders(trn_df, val_df, input_size, batch_size, rank, world_size)\n",
    "\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=384)\n",
    "    state_dict = torch.load(\"vit_large_patch16_224.pth\")\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    device = torch.device(f'cuda:{rank}')\n",
    "    model = torch.compile(model)\n",
    "    model.to(device)\n",
    "    model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, fused=True)\n",
    "\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    ttl_iters = num_epochs * len(dataloaders['train'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "    criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "    best_score = -1.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_meters = {\n",
    "            'loss': AverageMeter(),\n",
    "            'cos': AverageMeter()}\n",
    "\n",
    "        model.train()\n",
    "        for X, y in tqdm(dataloaders['train'], leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                X_out = model(X)\n",
    "                target = torch.ones(X.size(0)).to(device)\n",
    "                loss = criterion(X_out, y, target)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            trn_loss = loss.item()\n",
    "            trn_cos = cosine_similarity(\n",
    "                X_out.detach().cpu().numpy(), \n",
    "                y.detach().cpu().numpy())\n",
    "\n",
    "            train_meters['loss'].update(trn_loss, n=X.size(0))\n",
    "            train_meters['cos'].update(trn_cos, n=X.size(0))\n",
    "\n",
    "        print('Epoch {:d} / trn/loss={:.4f}, trn/cos={:.4f}'.format(\n",
    "            epoch + 1,\n",
    "            train_meters['loss'].avg,\n",
    "            train_meters['cos'].avg))\n",
    "\n",
    "        val_meters = {\n",
    "            'loss': AverageMeter(),\n",
    "            'cos': AverageMeter()}\n",
    "\n",
    "        model.eval()\n",
    "        for X, y in tqdm(dataloaders['val'], leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with autocast():\n",
    "                    X_out = model(X)\n",
    "                    target = torch.ones(X.size(0)).to(device)\n",
    "                    loss = criterion(X_out, y, target)\n",
    "\n",
    "                val_loss = loss.item()\n",
    "                val_cos = cosine_similarity(\n",
    "                    X_out.detach().cpu().numpy(), \n",
    "                    y.detach().cpu().numpy())\n",
    "\n",
    "            val_meters['loss'].update(val_loss, n=X.size(0))\n",
    "            val_meters['cos'].update(val_cos, n=X.size(0))\n",
    "\n",
    "        print('Epoch {:d} / val/loss={:.4f}, val/cos={:.4f}'.format(\n",
    "            epoch + 1,\n",
    "            val_meters['loss'].avg,\n",
    "            val_meters['cos'].avg))\n",
    "        \n",
    "        if val_meters['cos'].avg > best_score:\n",
    "            if rank == 0: # ONLY SAVE IF GPU 0\n",
    "                torch.save(model.module.state_dict(), f'{model_name}.pth')\n",
    "                torch.save(optimizer.state_dict(), f\"{model_name}_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = pd.read_csv('filtered_image_data.csv')\n",
    "    trn_df, val_df = train_test_split(df, test_size=0.1, random_state=CFG.seed)\n",
    "    world_size = 8\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12345'\n",
    "\n",
    "    processes = []\n",
    "    for rank in range(world_size):\n",
    "        p = Process(target=train, args=(rank, world_size, trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
