{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/lib/python3/dist-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import spatial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from timm.utils import AverageMeter\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "from torchvision import transforms\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = 'vit_large_patch16_224'\n",
    "    input_size = 224\n",
    "    batch_size = 128\n",
    "    num_epochs = 25\n",
    "    lr = 5e-4\n",
    "    seed = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['image_path'])\n",
    "        image = self.transform(image)\n",
    "        prompt = row['prompt']\n",
    "        return image, prompt\n",
    "\n",
    "\n",
    "class DiffusionCollator:\n",
    "    def __init__(self):\n",
    "        self.st_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu') # crashes cuda if all embeddings on GPU and lots of images\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        images, prompts = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        prompt_embeddings = self.st_model.encode(prompts, show_progress_bar=False, convert_to_tensor=True)\n",
    "        return images, prompt_embeddings\n",
    "    \n",
    "    \n",
    "def get_dataloaders(trn_df, val_df, input_size, batch_size):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(CFG.input_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(CFG.input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "    trn_dataset = DiffusionDataset(trn_df, train_transform)\n",
    "    val_dataset = DiffusionDataset(val_df, val_transform)\n",
    "    collator = DiffusionCollator()\n",
    "    \n",
    "    dataloaders = {}\n",
    "    dataloaders['train'] = DataLoader(\n",
    "        dataset=trn_dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=12,\n",
    "        drop_last=True,\n",
    "        collate_fn=collator\n",
    "    )\n",
    "    dataloaders['val'] = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=12,\n",
    "        drop_last=False,\n",
    "        collate_fn=collator\n",
    "    )\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(y_trues, y_preds):\n",
    "    return np.mean([\n",
    "        1 - spatial.distance.cosine(y_true, y_pred) \n",
    "        for y_true, y_pred in zip(y_trues, y_preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trn_df, val_df, model_name, input_size, batch_size, num_epochs, lr):\n",
    "\n",
    "    dataloaders = get_dataloaders(trn_df, val_df, input_size, batch_size)\n",
    "\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=384)\n",
    "    state_dict = torch.load(\"vit_large_patch16_224.pth\")\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.set_grad_checkpointing()\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scaler = amp.GradScaler()\n",
    "    ttl_iters = num_epochs * len(dataloaders['train'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=ttl_iters, eta_min=1e-6)\n",
    "    criterion = nn.CosineEmbeddingLoss()\n",
    "    \n",
    "    best_score = -1.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_meters = {\n",
    "            'loss': AverageMeter(),\n",
    "            'cos': AverageMeter()}\n",
    "\n",
    "        model.train()\n",
    "        for X, y in tqdm(dataloaders['train'], leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with amp.autocast():\n",
    "                X_out = model(X)\n",
    "                target = torch.ones(X.size(0)).to(device)\n",
    "                loss = criterion(X_out, y, target)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            trn_loss = loss.item()\n",
    "            trn_cos = cosine_similarity(\n",
    "                X_out.detach().cpu().numpy(), \n",
    "                y.detach().cpu().numpy())\n",
    "\n",
    "            train_meters['loss'].update(trn_loss, n=X.size(0))\n",
    "            train_meters['cos'].update(trn_cos, n=X.size(0))\n",
    "\n",
    "        print('Epoch {:d} / trn/loss={:.4f}, trn/cos={:.4f}'.format(\n",
    "            epoch + 1,\n",
    "            train_meters['loss'].avg,\n",
    "            train_meters['cos'].avg))\n",
    "\n",
    "        val_meters = {\n",
    "            'loss': AverageMeter(),\n",
    "            'cos': AverageMeter()}\n",
    "\n",
    "        model.eval()\n",
    "        for X, y in tqdm(dataloaders['val'], leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with amp.autocast():\n",
    "                    X_out = model(X)\n",
    "                    target = torch.ones(X.size(0)).to(device)\n",
    "                    loss = criterion(X_out, y, target)\n",
    "\n",
    "                val_loss = loss.item()\n",
    "                val_cos = cosine_similarity(\n",
    "                    X_out.detach().cpu().numpy(), \n",
    "                    y.detach().cpu().numpy())\n",
    "\n",
    "            val_meters['loss'].update(val_loss, n=X.size(0))\n",
    "            val_meters['cos'].update(val_cos, n=X.size(0))\n",
    "\n",
    "        print('Epoch {:d} / val/loss={:.4f}, val/cos={:.4f}'.format(\n",
    "            epoch + 1,\n",
    "            val_meters['loss'].avg,\n",
    "            val_meters['cos'].avg))\n",
    "        \n",
    "        if val_meters['cos'].avg > best_score:\n",
    "            best_score = val_meters['cos'].avg\n",
    "            torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "            torch.save(optimizer.state_dict(), f\"{model_name}_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('midjourney_ea_al_data.csv')\n",
    "trn_df, val_df = train_test_split(df, test_size=0.1, random_state=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / trn/loss=0.4169, trn/cos=0.5831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / val/loss=0.4050, val/cos=0.5949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / trn/loss=0.3920, trn/cos=0.6080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / val/loss=0.3829, val/cos=0.6171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / trn/loss=0.3714, trn/cos=0.6286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / val/loss=0.3696, val/cos=0.6304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46a336883d54ea9a626f8494220e180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(trn_df, val_df, CFG.model_name, CFG.input_size, CFG.batch_size, CFG.num_epochs, CFG.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
